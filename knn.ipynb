{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis of Star Wars Survey Dataset\n",
    "\n",
    "**Chance Mason, Nicolas Arrieche Villegas, Mitchell Walker, Tyler Wittig**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "# 4.2 K-Nearest Neighbors\n",
    "\n",
    "In this notebook we will analyze how well the K-Nearest Neighbors method, with a 5-fold cross validation, works on the following **labels**:\n",
    "* 'Fan of Star Wars'\n",
    "* 'Which character shot first?'\n",
    "* 'Star Trek Fan'\n",
    "* 'Gender'\n",
    "* 'Age'\n",
    "* 'Household Income'\n",
    "* 'Education'\n",
    "* 'Location (Census Region)'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape =  (1186, 37)\n"
     ]
    }
   ],
   "source": [
    "#read in numeric version of survey data\n",
    "with open('column_names.txt', 'r') as cn:\n",
    "    col_names = [line.strip() for line in cn]\n",
    "    col_names.remove('RespondentID')\n",
    "    \n",
    "data = pd.read_csv('survey_numeric.csv')\n",
    "print(\"Shape = \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifications  \n",
    "\n",
    "Below is a function to automate the KNN Classification process with a 5-fold cross validation on a given label. PCA to reduce dimensionality and scaling will be done using a pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreKNN(label):\n",
    "    # split into features and label\n",
    "    features = data.drop(label, axis=1)\n",
    "    labels = data[[label]] \n",
    "    \n",
    "    # create a PCA\n",
    "    pca = PCA()\n",
    "\n",
    "    # create a KNN classifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    \n",
    "    # create a scaler, PCA and KNN classifier\n",
    "    scaler = sk.preprocessing.MinMaxScaler()\n",
    "\n",
    "    # create a pipeline that does scaling, then PCA, then KNN\n",
    "    pipe = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "\n",
    "    # Set up the parameters we want to test\n",
    "    param_grid = {\n",
    "       'pca__n_components': list(range(1, 19)), #find how many principal componenet to keep\n",
    "       'knn__n_neighbors': list(range(1, 30)),  #find the best value of k\n",
    "    }\n",
    "\n",
    "    # pass same GridSearchCV into a cross_val_score then print out the accuracy\n",
    "    search = GridSearchCV(pipe, param_grid, cv=5)\n",
    "    scores = cross_val_score(estimator=search, X=features, y=labels.values.ravel(), cv=5, scoring = 'accuracy')\n",
    "    predictions = cross_val_predict(estimator=search, X=features, y=labels.values.ravel(), cv=5)\n",
    "    print('Accuracy:', scores.mean())\n",
    "    print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now pass each label into the above function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fan of Star Wars\n",
      "\n",
      "Accuracy: 0.8633786404499582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.67      0.71       284\n",
      "           0       0.99      1.00      1.00       350\n",
      "           1       0.84      0.88      0.86       552\n",
      "\n",
      "    accuracy                           0.87      1186\n",
      "   macro avg       0.86      0.85      0.86      1186\n",
      "weighted avg       0.86      0.87      0.86      1186\n",
      "\n",
      "\n",
      "Which character shot first?\n",
      "\n",
      "Accuracy: 0.6812907269751924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.79      0.62       325\n",
      "           0       0.83      0.83      0.83       664\n",
      "           1       0.15      0.02      0.03       197\n",
      "\n",
      "    accuracy                           0.68      1186\n",
      "   macro avg       0.50      0.54      0.49      1186\n",
      "weighted avg       0.63      0.68      0.64      1186\n",
      "\n",
      "\n",
      "Gender\n",
      "\n",
      "Accuracy: 0.6213602411571795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.53      0.55       497\n",
      "           0       0.98      0.89      0.93       140\n",
      "           1       0.61      0.68      0.64       549\n",
      "\n",
      "    accuracy                           0.64      1186\n",
      "   macro avg       0.73      0.70      0.71      1186\n",
      "weighted avg       0.64      0.64      0.64      1186\n",
      "\n",
      "\n",
      "Age\n",
      "\n",
      "Accuracy: 0.37422460854391715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93       140\n",
      "           1       0.34      0.32      0.33       218\n",
      "           2       0.28      0.35      0.32       268\n",
      "           3       0.30      0.28      0.29       291\n",
      "           4       0.32      0.28      0.30       269\n",
      "\n",
      "    accuracy                           0.38      1186\n",
      "   macro avg       0.44      0.43      0.43      1186\n",
      "weighted avg       0.38      0.38      0.38      1186\n",
      "\n",
      "\n",
      "Household Income\n",
      "\n",
      "Accuracy: 0.3254924310149592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.51      0.52       328\n",
      "           1       0.13      0.03      0.05       138\n",
      "           2       0.20      0.18      0.19       186\n",
      "           3       0.30      0.65      0.41       298\n",
      "           4       0.19      0.04      0.07       141\n",
      "           5       0.00      0.00      0.00        95\n",
      "\n",
      "    accuracy                           0.34      1186\n",
      "   macro avg       0.23      0.24      0.21      1186\n",
      "weighted avg       0.29      0.34      0.29      1186\n",
      "\n",
      "\n",
      "Education\n",
      "\n",
      "Accuracy: 0.3776696378640955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91       150\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.10      0.03      0.04       105\n",
      "           3       0.31      0.52      0.39       328\n",
      "           4       0.31      0.30      0.30       321\n",
      "           5       0.31      0.19      0.24       275\n",
      "\n",
      "    accuracy                           0.38      1186\n",
      "   macro avg       0.33      0.32      0.31      1186\n",
      "weighted avg       0.37      0.38      0.36      1186\n",
      "\n",
      "\n",
      "Location (Census Region)\n",
      "\n",
      "Accuracy: 0.2445818946314074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       143\n",
      "           1       0.15      0.29      0.20       170\n",
      "           2       0.11      0.11      0.11       110\n",
      "           3       0.06      0.02      0.03        93\n",
      "           4       0.13      0.13      0.13       122\n",
      "           5       0.16      0.22      0.18       181\n",
      "           6       0.22      0.24      0.23       175\n",
      "           7       0.00      0.00      0.00        79\n",
      "           8       0.00      0.00      0.00        75\n",
      "           9       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.24      1186\n",
      "   macro avg       0.18      0.19      0.18      1186\n",
      "weighted avg       0.22      0.24      0.23      1186\n",
      "\n",
      "\n",
      "Star Trek Fan\n",
      "\n",
      "Accuracy: 0.7691009214268312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.76      0.78       641\n",
      "           0       0.95      0.88      0.92       118\n",
      "           1       0.68      0.75      0.71       427\n",
      "\n",
      "    accuracy                           0.77      1186\n",
      "   macro avg       0.81      0.80      0.80      1186\n",
      "weighted avg       0.77      0.77      0.77      1186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_labels = ['Fan of Star Wars','Which character shot first?','Gender', 'Age','Household Income','Education','Location (Census Region)', 'Star Trek Fan']\n",
    "for l in test_labels:\n",
    "    print('\\n'+l+'\\n')\n",
    "    scoreKNN(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Results\n",
    "\n",
    "Several of our label columns include a neutral or missing answer as a 0, but unlike in our Naive Bayes analysis, the 0 class doesn't seem to be a burden on our classification. In several cases the 0 class precision and recall are higher than the other categories.\n",
    "\n",
    " - The classifier for 'Fan of Star Wars' peformed quite well, with an overall accuracy of 87% and precision above 75% for each of the classes.\n",
    " - The classifier for 'Which character shot first?' had an overall accuracy of 68%. Upon further examination we see that this classifier did severely poor job in identifying the 1 class, only 2% of records that chose 1 (Greedo) were correctly identified, and only 15% of those identified as picking 1 actually did. The 68% accuracy is influenced by the relatively high precision and recall values for the 0 class.\n",
    " - The classifier for 'Star Trek Fan' yielded our second highest accuracy, 77%. Each of the classes had precision and recall above 75%, well over for the 0 class. The lowest score was for precision of the 1 class, only 68% of records identified as fans of Star Trek were actually fans.\n",
    " - The classifier for 'Gender' only performed slightly worse than 'Which character shot first?', with an accuracy of 64%. Both precision and recall for the -1 class (male) were lower than 60%, and only 61% of records identified as 1 (female) were correctly labeled.\n",
    " - The rest of our classifiers for Age, Household Income, Education, and Location all performed poorly, with accuracies below 40% for each of them. These classifiers performed best in identifying the 0 class, which is a blank answer. The other classes had very low precision and recall, it seems the overall accuracies would be even lower if the blank answer class were removed.\n",
    " \n",
    "These results show that the K-Nearest Neighbor classifier for the 'Fan of Star Wars' label performed best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
